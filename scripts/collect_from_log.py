#!/usr/bin/env python3
"""
collect_from_log.py
-------------------
Extracts benchmark results (TTFT, Throughput, etc.) from a log file
generated by bench_pd.py, and saves them as a CSV.

Example usage:
    python3 scripts/collect_from_log.py --input results/run_model_Qwen2.5-7B-Instruct_conc4_pt64_mt128.log \
                                        --output results/run_model_Qwen2.5-7B-Instruct_conc4_pt64_mt128.csv
"""

import argparse
import csv
import re

def parse_log(log_path: str):
    """Parse a single log file and extract benchmark statistics."""
    data = {
        "p50_ttft": None,
        "p95_ttft": None,
        "min_ttft": None,
        "max_ttft": None,
        "p50_tps": None,
        "p95_tps": None,
        "mean_tps": None,
        "total_tokens": None,
        "wall_time_sec": None,
        "aggregate_throughput": None
    }

    # Regex patterns for TTFT section
    ttft_pattern = re.compile(
        r"== TTFT.*?==\s*p50=(?P<p50>[0-9.]+)s\s*p95=(?P<p95>[0-9.]+)s\s*min=(?P<min>[0-9.]+)s\s*max=(?P<max>[0-9.]+)s"
    )

    # Regex patterns for Throughput section
    throughput_pattern = re.compile(
        r"== Throughput.*?==\s*.*?p50=(?P<p50>[0-9.]+)\s*p95=(?P<p95>[0-9.]+)\s*mean=(?P<mean>[0-9.]+).*?"
        r"total generated tokens = (?P<tokens>[0-9]+).*?"
        r"wall time \(whole run\)\s*=\s*(?P<wall>[0-9.]+)s.*?"
        r"aggregate throughput\s*=\s*(?P<agg>[0-9.]+)", re.DOTALL
    )

    with open(log_path, "r") as f:
        log = f.read()

    ttft_match = ttft_pattern.search(log)
    if ttft_match:
        data["p50_ttft"] = float(ttft_match.group("p50"))
        data["p95_ttft"] = float(ttft_match.group("p95"))
        data["min_ttft"] = float(ttft_match.group("min"))
        data["max_ttft"] = float(ttft_match.group("max"))

    throughput_match = throughput_pattern.search(log)
    if throughput_match:
        data["p50_tps"] = float(throughput_match.group("p50"))
        data["p95_tps"] = float(throughput_match.group("p95"))
        data["mean_tps"] = float(throughput_match.group("mean"))
        data["total_tokens"] = int(throughput_match.group("tokens"))
        data["wall_time_sec"] = float(throughput_match.group("wall"))
        data["aggregate_throughput"] = float(throughput_match.group("agg"))

    return data


def save_to_csv(data: dict, output_path: str):
    """Write the parsed data dictionary to a single-row CSV."""
    with open(output_path, "w", newline="") as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=list(data.keys()))
        writer.writeheader()
        writer.writerow(data)


def main():
    parser = argparse.ArgumentParser(description="Extract benchmark results from bench_pd.py logs.")
    parser.add_argument("--input", required=True, help="Path to the log file")
    parser.add_argument("--output", required=True, help="Path to the output CSV file")
    args = parser.parse_args()

    parsed = parse_log(args.input)
    save_to_csv(parsed, args.output)

    print(f"[OK] Extracted metrics saved to {args.output}")


if __name__ == "__main__":
    main()